{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import func\n",
    "importlib.reload(func)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "pd.options.display.max_rows = 100\n",
    "%matplotlib inline\n",
    "importlib.reload(func)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_101_tier = pd.read_excel(\"df_101_tier.xlsx\")\n",
    "df_101_tier = df_101_tier.set_index(\"RTN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use all features and Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_101_tier.iloc[:, :-1]\n",
    "y = df_101_tier.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17860, 143)\n",
      "dict_items([(1, 8930), (0, 8930)])\n",
      "(17860, 143)\n",
      "Training size: 17860\n",
      "Test size: 3256\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = SMOTE().fit_sample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(Counter(y_train).items())\n",
    "print(X_train.shape)\n",
    "print(\"Training size: %r\" %X_train.shape[0])\n",
    "print(\"Test size: %r\" %X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 213   65]\n",
      " [1292 1686]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Tier 1D       0.14      0.77      0.24       278\n",
      "      other       0.96      0.57      0.71      2978\n",
      "\n",
      "avg / total       0.89      0.58      0.67      3256\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4chILAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a180e0b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=3, n_estimators=200, max_features=0.2, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "func.plot_confusion_matrix(confusion_matrix(y_test, y_predict, labels=[True, False]), classes=['Tier 1D','other'])\n",
    "print(classification_report(y_test, y_predict, labels=[True, False], target_names=['Tier 1D','other']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 204   74]\n",
      " [1145 1833]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Tier 1D       0.15      0.73      0.25       278\n",
      "      other       0.96      0.62      0.75      2978\n",
      "\n",
      "avg / total       0.89      0.63      0.71      3256\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1828b1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svc = LinearSVC(dual=False, C=0.01, penalty='l1')\n",
    "svc.fit(X_train, y_train)\n",
    "y_predict = svc.predict(X_test)\n",
    "func.plot_confusion_matrix(confusion_matrix(y_test, y_predict, labels=[True, False]), classes=['Tier 1D','other'])\n",
    "print(classification_report(y_test, y_predict, labels=[True, False], target_names=['Tier 1D','other']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 199   79]\n",
      " [1062 1916]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Tier 1D       0.16      0.72      0.26       278\n",
      "      other       0.96      0.64      0.77      2978\n",
      "\n",
      "avg / total       0.89      0.65      0.73      3256\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCxDDrJmZhn6f05Cxh/N/s8RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1f3945f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# {'C': 0.1, 'dual': False, 'penalty': 'l2'}\n",
    "lg = LogisticRegression(C=0.1, dual=False, penalty='l2')\n",
    "lg.fit(X_train, y_train)\n",
    "y_predict = lg.predict(X_test)\n",
    "func.plot_confusion_matrix(confusion_matrix(y_test, y_predict, labels=[True, False]), classes=['Tier 1D','other'])\n",
    "print(classification_report(y_test, y_predict, labels=[True, False], target_names=['Tier 1D','other']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = func.Clf(X, y)\n",
    "clfs.runKfold(RandomForestClassifier, {\"n_estimators\": [200], \n",
    "                                      'max_features': ['sqrt', 'log2', 0.2], \n",
    "                                      'max_depth': [None, 3, 4, 5]}, True)\n",
    "clfs.runKfold(RandomForestClassifier, {\"n_estimators\": [200], \n",
    "                                      'max_features': ['sqrt', 'log2', 0.2], \n",
    "                                      'max_depth': [None, 3, 4, 5]}, True)\n",
    "clfs.runKfold(LinearSVC, {\"dual\": [True], \"penalty\": ['l2'], 'C': [0.01, 0.1, 1, 10, 100]}, True)\n",
    "clfs.runKfold(LinearSVC, {\"dual\": [False], \"penalty\": ['l2'], 'C': [0.01, 0.1, 1, 10, 100]}, True)\n",
    "clfs.runKfold(LinearSVC, {\"dual\": [False], \"penalty\": ['l1'], 'C': [0.01, 0.1, 1, 10, 100]}, True)\n",
    "clfs.runKfold(LogisticRegression, {\"penalty\": ['l1', 'l2'], 'dual': [False], \"C\": [0.01, 0.1, 1, 10, 100]}, True)\n",
    "clfs.runKfold(LogisticRegression, {\"penalty\": ['l2'], 'dual': [True], \"C\": [0.01, 0.1, 1, 10, 100]}, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-8ee962b8b787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m clfs.runKfold(RandomForestClassifier, {\"n_estimators\": [200], \n\u001b[1;32m      2\u001b[0m                                       \u001b[0;34m'max_features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'log2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                       'max_depth': [None, 3, 4, 5]}, False)\n\u001b[0m\u001b[1;32m      4\u001b[0m clfs.runKfold(RandomForestClassifier, {\"n_estimators\": [200], \n\u001b[1;32m      5\u001b[0m                                       \u001b[0;34m'max_features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'log2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Python/DS598/func.py\u001b[0m in \u001b[0;36mrunKfold\u001b[0;34m(self, classifier, param, smote, k)\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClusterCentroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_sample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/imblearn/under_sampling/prototype_generation/cluster_centroids.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n_clusters'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 X_new, y_new = self._generate_sample(\n\u001b[1;32m    186\u001b[0m                     X, y, self.estimator_.cluster_centers_, target_class)\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 x_squared_norms=x_squared_norms, random_state=random_state)\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     centers = _init_centroids(X, n_clusters, init, random_state=random_state,\n\u001b[0;32m--> 395\u001b[0;31m                               x_squared_norms=x_squared_norms)\n\u001b[0m\u001b[1;32m    396\u001b[0m     \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_init_centroids\u001b[0;34m(X, k, init, random_state, x_squared_norms, init_size)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         centers = _k_init(X, k, random_state=random_state,\n\u001b[0;32m--> 684\u001b[0;31m                           x_squared_norms=x_squared_norms)\n\u001b[0m\u001b[1;32m    685\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_k_init\u001b[0;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Compute distances to center candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         distance_to_candidates = euclidean_distances(\n\u001b[0;32m--> 113\u001b[0;31m             X[candidate_ids], X, Y_norm_squared=x_squared_norms, squared=True)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Decide which candidate is the best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mYY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clfs.runKfold(RandomForestClassifier, {\"n_estimators\": [200], \n",
    "                                      'max_features': ['sqrt', 'log2', 0.2], \n",
    "                                      'max_depth': [None, 3, 4, 5]}, False)\n",
    "clfs.runKfold(RandomForestClassifier, {\"n_estimators\": [200], \n",
    "                                      'max_features': ['sqrt', 'log2', 0.2], \n",
    "                                      'max_depth': [None, 3, 4, 5]}, False)\n",
    "clfs.runKfold(LinearSVC, {\"dual\": [True], \"penalty\": ['l2'], 'C': [0.01, 0.1, 1, 10, 100]}, False)\n",
    "clfs.runKfold(LinearSVC, {\"dual\": [False], \"penalty\": ['l2'], 'C': [0.01, 0.1, 1, 10, 100]}, False)\n",
    "clfs.runKfold(LinearSVC, {\"dual\": [False], \"penalty\": ['l1'], 'C': [0.01, 0.1, 1, 10, 100]}, False)\n",
    "clfs.runKfold(LogisticRegression, {\"penalty\": ['l1', 'l2'], 'dual': [False], \"C\": [0.01, 0.1, 1, 10, 100]}, False)\n",
    "clfs.runKfold(LogisticRegression, {\"penalty\": ['l2'], 'dual': [True], \"C\": [0.01, 0.1, 1, 10, 100]}, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>params</th>\n",
       "      <th>smote</th>\n",
       "      <th>Trecall</th>\n",
       "      <th>Tprecision</th>\n",
       "      <th>Tf1</th>\n",
       "      <th>Frecall</th>\n",
       "      <th>Fprecision</th>\n",
       "      <th>Ff1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'sqrt', 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.138360</td>\n",
       "      <td>0.204874</td>\n",
       "      <td>0.163208</td>\n",
       "      <td>0.948186</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.934710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'log2', 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.135662</td>\n",
       "      <td>0.200825</td>\n",
       "      <td>0.159717</td>\n",
       "      <td>0.948354</td>\n",
       "      <td>0.921510</td>\n",
       "      <td>0.934683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': None, 'max_features': 0.2, 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.141974</td>\n",
       "      <td>0.224345</td>\n",
       "      <td>0.173460</td>\n",
       "      <td>0.953981</td>\n",
       "      <td>0.922456</td>\n",
       "      <td>0.937945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.142305</td>\n",
       "      <td>0.239182</td>\n",
       "      <td>0.577847</td>\n",
       "      <td>0.961038</td>\n",
       "      <td>0.721718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731367</td>\n",
       "      <td>0.143720</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.592627</td>\n",
       "      <td>0.959351</td>\n",
       "      <td>0.732635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.772714</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>0.242135</td>\n",
       "      <td>0.569365</td>\n",
       "      <td>0.964117</td>\n",
       "      <td>0.715846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731363</td>\n",
       "      <td>0.147047</td>\n",
       "      <td>0.244860</td>\n",
       "      <td>0.603460</td>\n",
       "      <td>0.960053</td>\n",
       "      <td>0.741082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.725084</td>\n",
       "      <td>0.148036</td>\n",
       "      <td>0.245842</td>\n",
       "      <td>0.609926</td>\n",
       "      <td>0.959617</td>\n",
       "      <td>0.745729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.728685</td>\n",
       "      <td>0.147748</td>\n",
       "      <td>0.245679</td>\n",
       "      <td>0.607239</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>0.743892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.718793</td>\n",
       "      <td>0.150312</td>\n",
       "      <td>0.248620</td>\n",
       "      <td>0.620255</td>\n",
       "      <td>0.959366</td>\n",
       "      <td>0.753383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.710686</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.249356</td>\n",
       "      <td>0.627225</td>\n",
       "      <td>0.958721</td>\n",
       "      <td>0.758253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.637870</td>\n",
       "      <td>0.161510</td>\n",
       "      <td>0.257381</td>\n",
       "      <td>0.688529</td>\n",
       "      <td>0.953221</td>\n",
       "      <td>0.798973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'sqrt', 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146457</td>\n",
       "      <td>0.205033</td>\n",
       "      <td>0.169730</td>\n",
       "      <td>0.946087</td>\n",
       "      <td>0.922235</td>\n",
       "      <td>0.933980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'log2', 'n...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.133874</td>\n",
       "      <td>0.203716</td>\n",
       "      <td>0.159708</td>\n",
       "      <td>0.949530</td>\n",
       "      <td>0.921440</td>\n",
       "      <td>0.935226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': None, 'max_features': 0.2, 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.150953</td>\n",
       "      <td>0.209619</td>\n",
       "      <td>0.174088</td>\n",
       "      <td>0.945499</td>\n",
       "      <td>0.922565</td>\n",
       "      <td>0.933855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.747531</td>\n",
       "      <td>0.143922</td>\n",
       "      <td>0.241367</td>\n",
       "      <td>0.584397</td>\n",
       "      <td>0.961199</td>\n",
       "      <td>0.726844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.713368</td>\n",
       "      <td>0.143687</td>\n",
       "      <td>0.239183</td>\n",
       "      <td>0.602788</td>\n",
       "      <td>0.957496</td>\n",
       "      <td>0.739784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.756524</td>\n",
       "      <td>0.143716</td>\n",
       "      <td>0.241535</td>\n",
       "      <td>0.578687</td>\n",
       "      <td>0.962182</td>\n",
       "      <td>0.722673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.737642</td>\n",
       "      <td>0.147209</td>\n",
       "      <td>0.245417</td>\n",
       "      <td>0.600605</td>\n",
       "      <td>0.960809</td>\n",
       "      <td>0.739099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.721474</td>\n",
       "      <td>0.148200</td>\n",
       "      <td>0.245879</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.959212</td>\n",
       "      <td>0.747417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.714274</td>\n",
       "      <td>0.152551</td>\n",
       "      <td>0.251190</td>\n",
       "      <td>0.627729</td>\n",
       "      <td>0.959270</td>\n",
       "      <td>0.758409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.715196</td>\n",
       "      <td>0.151345</td>\n",
       "      <td>0.249802</td>\n",
       "      <td>0.625042</td>\n",
       "      <td>0.959162</td>\n",
       "      <td>0.756818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.708008</td>\n",
       "      <td>0.150665</td>\n",
       "      <td>0.248450</td>\n",
       "      <td>0.626973</td>\n",
       "      <td>0.958297</td>\n",
       "      <td>0.757994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.640591</td>\n",
       "      <td>0.162475</td>\n",
       "      <td>0.258953</td>\n",
       "      <td>0.689704</td>\n",
       "      <td>0.953558</td>\n",
       "      <td>0.800080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 0.01, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.736749</td>\n",
       "      <td>0.154876</td>\n",
       "      <td>0.255897</td>\n",
       "      <td>0.623950</td>\n",
       "      <td>0.962092</td>\n",
       "      <td>0.756855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 0.1, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.707060</td>\n",
       "      <td>0.155924</td>\n",
       "      <td>0.254910</td>\n",
       "      <td>0.639486</td>\n",
       "      <td>0.959237</td>\n",
       "      <td>0.766270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.689932</td>\n",
       "      <td>0.153543</td>\n",
       "      <td>0.249272</td>\n",
       "      <td>0.634195</td>\n",
       "      <td>0.957117</td>\n",
       "      <td>0.758857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 10, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.685513</td>\n",
       "      <td>0.152401</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>0.636715</td>\n",
       "      <td>0.956090</td>\n",
       "      <td>0.762432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 100, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.628781</td>\n",
       "      <td>0.144287</td>\n",
       "      <td>0.220061</td>\n",
       "      <td>0.575160</td>\n",
       "      <td>0.946678</td>\n",
       "      <td>0.672802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 0.01, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.721481</td>\n",
       "      <td>0.159426</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>0.644273</td>\n",
       "      <td>0.961179</td>\n",
       "      <td>0.771379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 0.1, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.723279</td>\n",
       "      <td>0.157219</td>\n",
       "      <td>0.258202</td>\n",
       "      <td>0.637051</td>\n",
       "      <td>0.961016</td>\n",
       "      <td>0.766008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.702619</td>\n",
       "      <td>0.156424</td>\n",
       "      <td>0.255853</td>\n",
       "      <td>0.645700</td>\n",
       "      <td>0.958740</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 10, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.718777</td>\n",
       "      <td>0.156715</td>\n",
       "      <td>0.257311</td>\n",
       "      <td>0.638310</td>\n",
       "      <td>0.960441</td>\n",
       "      <td>0.766889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 100, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.725974</td>\n",
       "      <td>0.155323</td>\n",
       "      <td>0.255888</td>\n",
       "      <td>0.630920</td>\n",
       "      <td>0.960987</td>\n",
       "      <td>0.761713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 0.01, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.739450</td>\n",
       "      <td>0.160760</td>\n",
       "      <td>0.264090</td>\n",
       "      <td>0.639150</td>\n",
       "      <td>0.963305</td>\n",
       "      <td>0.768419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 0.1, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.725068</td>\n",
       "      <td>0.156871</td>\n",
       "      <td>0.257855</td>\n",
       "      <td>0.635287</td>\n",
       "      <td>0.961160</td>\n",
       "      <td>0.764791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.722383</td>\n",
       "      <td>0.158108</td>\n",
       "      <td>0.259362</td>\n",
       "      <td>0.640242</td>\n",
       "      <td>0.961105</td>\n",
       "      <td>0.768385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 10, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.719679</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>0.255969</td>\n",
       "      <td>0.634951</td>\n",
       "      <td>0.960358</td>\n",
       "      <td>0.764427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 100, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.718780</td>\n",
       "      <td>0.156406</td>\n",
       "      <td>0.256816</td>\n",
       "      <td>0.637303</td>\n",
       "      <td>0.960460</td>\n",
       "      <td>0.766007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.737671</td>\n",
       "      <td>0.150598</td>\n",
       "      <td>0.249867</td>\n",
       "      <td>0.609674</td>\n",
       "      <td>0.961565</td>\n",
       "      <td>0.745413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731360</td>\n",
       "      <td>0.157272</td>\n",
       "      <td>0.258874</td>\n",
       "      <td>0.633692</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.764033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.1, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.719682</td>\n",
       "      <td>0.159685</td>\n",
       "      <td>0.261352</td>\n",
       "      <td>0.645868</td>\n",
       "      <td>0.961020</td>\n",
       "      <td>0.772493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.1, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.715208</td>\n",
       "      <td>0.161049</td>\n",
       "      <td>0.262877</td>\n",
       "      <td>0.651747</td>\n",
       "      <td>0.960778</td>\n",
       "      <td>0.776615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.711611</td>\n",
       "      <td>0.156342</td>\n",
       "      <td>0.256246</td>\n",
       "      <td>0.640494</td>\n",
       "      <td>0.959671</td>\n",
       "      <td>0.768017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.709803</td>\n",
       "      <td>0.158016</td>\n",
       "      <td>0.258445</td>\n",
       "      <td>0.646372</td>\n",
       "      <td>0.959757</td>\n",
       "      <td>0.772412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.698116</td>\n",
       "      <td>0.158692</td>\n",
       "      <td>0.258579</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.958622</td>\n",
       "      <td>0.777389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.157316</td>\n",
       "      <td>0.257824</td>\n",
       "      <td>0.641669</td>\n",
       "      <td>0.960225</td>\n",
       "      <td>0.769116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 100, 'dual': False, 'penalty': 'l1'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.706200</td>\n",
       "      <td>0.159057</td>\n",
       "      <td>0.259591</td>\n",
       "      <td>0.650571</td>\n",
       "      <td>0.959486</td>\n",
       "      <td>0.775302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 100, 'dual': False, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.714312</td>\n",
       "      <td>0.158056</td>\n",
       "      <td>0.258807</td>\n",
       "      <td>0.644273</td>\n",
       "      <td>0.960224</td>\n",
       "      <td>0.771083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.752034</td>\n",
       "      <td>0.148493</td>\n",
       "      <td>0.247913</td>\n",
       "      <td>0.596070</td>\n",
       "      <td>0.962609</td>\n",
       "      <td>0.735925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.1, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.732208</td>\n",
       "      <td>0.152470</td>\n",
       "      <td>0.251554</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.961352</td>\n",
       "      <td>0.748782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660397</td>\n",
       "      <td>0.163430</td>\n",
       "      <td>0.260752</td>\n",
       "      <td>0.679375</td>\n",
       "      <td>0.955994</td>\n",
       "      <td>0.792198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.694596</td>\n",
       "      <td>0.153519</td>\n",
       "      <td>0.249555</td>\n",
       "      <td>0.632264</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>0.757781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 100, 'dual': True, 'penalty': 'l2'}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.786964</td>\n",
       "      <td>0.124875</td>\n",
       "      <td>0.213393</td>\n",
       "      <td>0.462966</td>\n",
       "      <td>0.960893</td>\n",
       "      <td>0.611675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       clf                                             params  \\\n",
       "0   RandomForestClassifier  {'max_depth': None, 'max_features': 'sqrt', 'n...   \n",
       "1   RandomForestClassifier  {'max_depth': None, 'max_features': 'log2', 'n...   \n",
       "2   RandomForestClassifier  {'max_depth': None, 'max_features': 0.2, 'n_es...   \n",
       "3   RandomForestClassifier  {'max_depth': 3, 'max_features': 'sqrt', 'n_es...   \n",
       "4   RandomForestClassifier  {'max_depth': 3, 'max_features': 'log2', 'n_es...   \n",
       "5   RandomForestClassifier  {'max_depth': 3, 'max_features': 0.2, 'n_estim...   \n",
       "6   RandomForestClassifier  {'max_depth': 4, 'max_features': 'sqrt', 'n_es...   \n",
       "7   RandomForestClassifier  {'max_depth': 4, 'max_features': 'log2', 'n_es...   \n",
       "8   RandomForestClassifier  {'max_depth': 4, 'max_features': 0.2, 'n_estim...   \n",
       "9   RandomForestClassifier  {'max_depth': 5, 'max_features': 'sqrt', 'n_es...   \n",
       "10  RandomForestClassifier  {'max_depth': 5, 'max_features': 'log2', 'n_es...   \n",
       "11  RandomForestClassifier  {'max_depth': 5, 'max_features': 0.2, 'n_estim...   \n",
       "12  RandomForestClassifier  {'max_depth': None, 'max_features': 'sqrt', 'n...   \n",
       "13  RandomForestClassifier  {'max_depth': None, 'max_features': 'log2', 'n...   \n",
       "14  RandomForestClassifier  {'max_depth': None, 'max_features': 0.2, 'n_es...   \n",
       "15  RandomForestClassifier  {'max_depth': 3, 'max_features': 'sqrt', 'n_es...   \n",
       "16  RandomForestClassifier  {'max_depth': 3, 'max_features': 'log2', 'n_es...   \n",
       "17  RandomForestClassifier  {'max_depth': 3, 'max_features': 0.2, 'n_estim...   \n",
       "18  RandomForestClassifier  {'max_depth': 4, 'max_features': 'sqrt', 'n_es...   \n",
       "19  RandomForestClassifier  {'max_depth': 4, 'max_features': 'log2', 'n_es...   \n",
       "20  RandomForestClassifier  {'max_depth': 4, 'max_features': 0.2, 'n_estim...   \n",
       "21  RandomForestClassifier  {'max_depth': 5, 'max_features': 'sqrt', 'n_es...   \n",
       "22  RandomForestClassifier  {'max_depth': 5, 'max_features': 'log2', 'n_es...   \n",
       "23  RandomForestClassifier  {'max_depth': 5, 'max_features': 0.2, 'n_estim...   \n",
       "24               LinearSVC         {'C': 0.01, 'dual': True, 'penalty': 'l2'}   \n",
       "25               LinearSVC          {'C': 0.1, 'dual': True, 'penalty': 'l2'}   \n",
       "26               LinearSVC            {'C': 1, 'dual': True, 'penalty': 'l2'}   \n",
       "27               LinearSVC           {'C': 10, 'dual': True, 'penalty': 'l2'}   \n",
       "28               LinearSVC          {'C': 100, 'dual': True, 'penalty': 'l2'}   \n",
       "29               LinearSVC        {'C': 0.01, 'dual': False, 'penalty': 'l2'}   \n",
       "30               LinearSVC         {'C': 0.1, 'dual': False, 'penalty': 'l2'}   \n",
       "31               LinearSVC           {'C': 1, 'dual': False, 'penalty': 'l2'}   \n",
       "32               LinearSVC          {'C': 10, 'dual': False, 'penalty': 'l2'}   \n",
       "33               LinearSVC         {'C': 100, 'dual': False, 'penalty': 'l2'}   \n",
       "34               LinearSVC        {'C': 0.01, 'dual': False, 'penalty': 'l1'}   \n",
       "35               LinearSVC         {'C': 0.1, 'dual': False, 'penalty': 'l1'}   \n",
       "36               LinearSVC           {'C': 1, 'dual': False, 'penalty': 'l1'}   \n",
       "37               LinearSVC          {'C': 10, 'dual': False, 'penalty': 'l1'}   \n",
       "38               LinearSVC         {'C': 100, 'dual': False, 'penalty': 'l1'}   \n",
       "39      LogisticRegression        {'C': 0.01, 'dual': False, 'penalty': 'l1'}   \n",
       "40      LogisticRegression        {'C': 0.01, 'dual': False, 'penalty': 'l2'}   \n",
       "41      LogisticRegression         {'C': 0.1, 'dual': False, 'penalty': 'l1'}   \n",
       "42      LogisticRegression         {'C': 0.1, 'dual': False, 'penalty': 'l2'}   \n",
       "43      LogisticRegression           {'C': 1, 'dual': False, 'penalty': 'l1'}   \n",
       "44      LogisticRegression           {'C': 1, 'dual': False, 'penalty': 'l2'}   \n",
       "45      LogisticRegression          {'C': 10, 'dual': False, 'penalty': 'l1'}   \n",
       "46      LogisticRegression          {'C': 10, 'dual': False, 'penalty': 'l2'}   \n",
       "47      LogisticRegression         {'C': 100, 'dual': False, 'penalty': 'l1'}   \n",
       "48      LogisticRegression         {'C': 100, 'dual': False, 'penalty': 'l2'}   \n",
       "49      LogisticRegression         {'C': 0.01, 'dual': True, 'penalty': 'l2'}   \n",
       "50      LogisticRegression          {'C': 0.1, 'dual': True, 'penalty': 'l2'}   \n",
       "51      LogisticRegression            {'C': 1, 'dual': True, 'penalty': 'l2'}   \n",
       "52      LogisticRegression           {'C': 10, 'dual': True, 'penalty': 'l2'}   \n",
       "53      LogisticRegression          {'C': 100, 'dual': True, 'penalty': 'l2'}   \n",
       "\n",
       "   smote   Trecall  Tprecision       Tf1   Frecall  Fprecision       Ff1  \n",
       "0   True  0.138360    0.204874  0.163208  0.948186    0.921714  0.934710  \n",
       "1   True  0.135662    0.200825  0.159717  0.948354    0.921510  0.934683  \n",
       "2   True  0.141974    0.224345  0.173460  0.953981    0.922456  0.937945  \n",
       "3   True  0.749336    0.142305  0.239182  0.577847    0.961038  0.721718  \n",
       "4   True  0.731367    0.143720  0.240223  0.592627    0.959351  0.732635  \n",
       "5   True  0.772714    0.143577  0.242135  0.569365    0.964117  0.715846  \n",
       "6   True  0.731363    0.147047  0.244860  0.603460    0.960053  0.741082  \n",
       "7   True  0.725084    0.148036  0.245842  0.609926    0.959617  0.745729  \n",
       "8   True  0.728685    0.147748  0.245679  0.607239    0.959930  0.743892  \n",
       "9   True  0.718793    0.150312  0.248620  0.620255    0.959366  0.753383  \n",
       "10  True  0.710686    0.151228  0.249356  0.627225    0.958721  0.758253  \n",
       "11  True  0.637870    0.161510  0.257381  0.688529    0.953221  0.798973  \n",
       "12  True  0.146457    0.205033  0.169730  0.946087    0.922235  0.933980  \n",
       "13  True  0.133874    0.203716  0.159708  0.949530    0.921440  0.935226  \n",
       "14  True  0.150953    0.209619  0.174088  0.945499    0.922565  0.933855  \n",
       "15  True  0.747531    0.143922  0.241367  0.584397    0.961199  0.726844  \n",
       "16  True  0.713368    0.143687  0.239183  0.602788    0.957496  0.739784  \n",
       "17  True  0.756524    0.143716  0.241535  0.578687    0.962182  0.722673  \n",
       "18  True  0.737642    0.147209  0.245417  0.600605    0.960809  0.739099  \n",
       "19  True  0.721474    0.148200  0.245879  0.612277    0.959212  0.747417  \n",
       "20  True  0.714274    0.152551  0.251190  0.627729    0.959270  0.758409  \n",
       "21  True  0.715196    0.151345  0.249802  0.625042    0.959162  0.756818  \n",
       "22  True  0.708008    0.150665  0.248450  0.626973    0.958297  0.757994  \n",
       "23  True  0.640591    0.162475  0.258953  0.689704    0.953558  0.800080  \n",
       "24  True  0.736749    0.154876  0.255897  0.623950    0.962092  0.756855  \n",
       "25  True  0.707060    0.155924  0.254910  0.639486    0.959237  0.766270  \n",
       "26  True  0.689932    0.153543  0.249272  0.634195    0.957117  0.758857  \n",
       "27  True  0.685513    0.152401  0.248200  0.636715    0.956090  0.762432  \n",
       "28  True  0.628781    0.144287  0.220061  0.575160    0.946678  0.672802  \n",
       "29  True  0.721481    0.159426  0.261111  0.644273    0.961179  0.771379  \n",
       "30  True  0.723279    0.157219  0.258202  0.637051    0.961016  0.766008  \n",
       "31  True  0.702619    0.156424  0.255853  0.645700    0.958740  0.771626  \n",
       "32  True  0.718777    0.156715  0.257311  0.638310    0.960441  0.766889  \n",
       "33  True  0.725974    0.155323  0.255888  0.630920    0.960987  0.761713  \n",
       "34  True  0.739450    0.160760  0.264090  0.639150    0.963305  0.768419  \n",
       "35  True  0.725068    0.156871  0.257855  0.635287    0.961160  0.764791  \n",
       "36  True  0.722383    0.158108  0.259362  0.640242    0.961105  0.768385  \n",
       "37  True  0.719679    0.155680  0.255969  0.634951    0.960358  0.764427  \n",
       "38  True  0.718780    0.156406  0.256816  0.637303    0.960460  0.766007  \n",
       "39  True  0.737671    0.150598  0.249867  0.609674    0.961565  0.745413  \n",
       "40  True  0.731360    0.157272  0.258874  0.633692    0.961885  0.764033  \n",
       "41  True  0.719682    0.159685  0.261352  0.645868    0.961020  0.772493  \n",
       "42  True  0.715208    0.161049  0.262877  0.651747    0.960778  0.776615  \n",
       "43  True  0.711611    0.156342  0.256246  0.640494    0.959671  0.768017  \n",
       "44  True  0.709803    0.158016  0.258445  0.646372    0.959757  0.772412  \n",
       "45  True  0.698116    0.158692  0.258579  0.653846    0.958622  0.777389  \n",
       "46  True  0.715189    0.157316  0.257824  0.641669    0.960225  0.769116  \n",
       "47  True  0.706200    0.159057  0.259591  0.650571    0.959486  0.775302  \n",
       "48  True  0.714312    0.158056  0.258807  0.644273    0.960224  0.771083  \n",
       "49  True  0.752034    0.148493  0.247913  0.596070    0.962609  0.735925  \n",
       "50  True  0.732208    0.152470  0.251554  0.615385    0.961352  0.748782  \n",
       "51  True  0.660397    0.163430  0.260752  0.679375    0.955994  0.792198  \n",
       "52  True  0.694596    0.153519  0.249555  0.632264    0.957659  0.757781  \n",
       "53  True  0.786964    0.124875  0.213393  0.462966    0.960893  0.611675  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs.clf_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'max_features': 0.2, 'n_estimators': 200}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs.clf_eval.loc[5, 'params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
